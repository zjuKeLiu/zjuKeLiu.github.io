<br> ✉ Correspond author; <b>*</b> Equal contribution.
<h2>Conference Papers<small></small></h2>
<ul>
    <li>
        <span style="background-color: lightblue;">[<strong>C10</strong>] A Denoising Pre-training Framework for Accelerating Novel Material Discovery.</span> <br>
        <span style="background-color: lightgray;">Shuaike Shen*,  <strong>Ke Liu* ✉</strong>, Muzhi Zhu, Hao Chen</span> <br>
        <i style="background-color: lightpink;">Proc. Annual AAAI Conference on Artificial Intelligence. (<strong>AAAI'25</strong>)</i> <br>
        <a href="https://github.com/zjuKeLiu/Matformer_MLM">[code]</a> 
        <a href="https://arxiv.org/abs/2410.21085">[To appear]</a> 
        <!-- <a href="bibs/FADiff.bib">[bib]</a>  -->
        <a href="https://ai4mol.github.io/projects/DPF/">[Project Page]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C9</strong>] KA2ER: Knowledge Adaptive Amalgamation of ExpeRts for Medical Images Segmentation.</span> <br>
        <span style="background-color: lightgray;">Shangde Gao, Yichao Fu, <strong>Ke Liu</strong>, Hongxia Xu, Jian Wu</span> <br>
        <i style="background-color: lightpink;">Proc. International Conference on Medical Image Computing and Computing Assisted Intervention (<strong>MICCAI'24</strong>), CARE challenge, 2024.</i> <br>
        <a href="https://github.com/AI4MOL/FADiff">[code]</a> 
        <a href="https://arxiv.org/abs/2410.21085">[paper]</a> 
        <a href="bibs/FADiff.bib">[bib]</a> 
        <a href="https://ai4mol.github.io/projects/FADiff/">[Project Page]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C8</strong>] Boost Your Crystal Model with Denoising Pre-training.</span> <br>
        <span style="background-color: lightgray;">Shuaike Shen*, <strong>Ke Liu*</strong>, Muzhi Zhu, Hao Chen</span> <br>
        <i style="background-color: lightpink;">Proc. International Conference on Machine Learning (<strong>ICML'24</strong>) AI4Science Workshop, 2024.</i> <br>
        <a href="https://github.com/AI4MOL/FADiff">[code]</a> 
        <a href="https://openreview.net/forum?id=u2qYzRRg02">[paper]</a> 
        <a href="bibs/DPF.bib">[bib]</a> 
        <a href="https://ai4mol.github.io/projects/DPF/">[Project Page]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C7</strong>] Floating Anchor Diffusion Model for Multi-motif Scaffolding.</span> <br>
        <span style="background-color: lightgray;"><strong>Ke Liu</strong>, Shuaike Shen, Weian Mao, Xiaoran Jiao, Zheng Sun, Hao Chen, Chunhua Shen</span> <br>
        <i style="background-color: lightpink;">Proc. International Conference on Machine Learning (<strong>ICML'24</strong>), 2024.</i> <br>
        <a href="https://github.com/AI4MOL/FADiff">[code]</a> 
        <a href="https://zjukeliu.github.io">[paper]</a> 
        <a href="bibs/FADiff.bib">[bib]</a> 
        <a href="https://ai4mol.github.io/projects/FADiff/">[Project Page]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C6</strong>] Contrastive Knowledge Amalgamation for Unsupervised Image Classification.</span> <br>
        <span style="background-color: lightgray;">Shangde Gao*, Yichao Fu*, <strong>Ke Liu</strong>*, Yuqiang Han.</span> <br>
        <i style="background-color: lightpink;">Proc. International Conference on Artificial Neural Networks (<strong>ICANN'23</strong>) 2023. <br>
        <strong>(Oral presentation)</strong></i>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C5</strong>] Empowering General-purpose User Representation with Full-life Cycle Behavior Modeling.</span> <br>
        <span style="background-color: lightgray;">Bei Yang, Jie Gu, <strong>Ke Liu</strong>, Xiaoxiao Xu, Rux Xu, Hong Liu, Huan Xu</span> <br>
        <i style="background-color: lightpink;">Proc. Knowledge Discovery and Data Mining (<strong>SIGKDD'23</strong>). 2023.</i>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C4</strong>] Group Equivariant Vision Transformer.</span> <br>
        <span style="background-color: lightgray;">Rux Xu*, Kaifan Yang*, <strong>Ke Liu</strong>*✉, Fengxiang He.</span> <br>
        <i style="background-color: lightpink;">Proc. Conference on Uncertainty in Artificial Intelligence (<strong>UAI'23</strong>), 2023.</i> <br>
        <a href="https://github.com/zjuKeLiu/GEVit">[code]</a> 
        <a href="https://openreview.net/forum?id=uVG_7x41bN">[paper]</a> 
        <a href="bibs/GEViT.bib">[bib]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C3</strong>] PCVAE: a Physics-Informed Neural Network for Determining the Symmetry and Geometry of Crystals.</span> <br>
        <span style="background-color: lightgray;"><b>Ke Liu</b>, Shangde Gao, Kaifan Yang, Yuqiang Han.</span> <br>
        <i style="background-color: lightpink;">Proc. International Joint Conference on Neural Networks (<strong>IJCNN'23</strong>) 2023. <br>
        <strong>(Oral presentation)</strong></i> <br>
        <a href="https://github.com/zjuKeLiu/PCVAE">[code]</a> 
        <a href="https://ieeexplore.ieee.org/document/10191051">[paper]</a> 
        <a href="bibs/pcvae.bib">[bib]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C2</strong>] Learning Interest-oriented Universal User Representation via Self-supervision.</span> <br>
        <span style="background-color: lightgray;">Qinghui Sun, Jie Gu, Xiaoxiao Xu, Rux Xu, <strong>Ke Liu</strong>, Bei Yang, Hong Liu, huan xu.</span> <br>
        <i style="background-color: lightpink;">Proc. International Conference on Multimedia (<strong>MM'22</strong>), 2022.</i> <br>
        <a href="https://dl.acm.org/doi/10.1145/3503161.3548767">[paper]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>C1</strong>] S2SNet: A Pretrained Neural Network for Superconductivity Discovery.</span> <br>
        <span style="background-color: lightgray;"><strong>Ke Liu</strong>, Kaifan Yang, Jiahong Zhang, Rux Xu.</span> <br>
        <i style="background-color: lightpink;">Proc. International Joint Conference on Artificial Intelligence (<strong>IJCAI'22</strong>), 2022.</i> <br>
        <a href="https://github.com/zjuKeLiu/S2SNet">[code]</a> 
        <a href="https://www.ijcai.org/proceedings/2022/708">[paper]</a> 
        <a href="https://www.ijcai.org/proceedings/2022/bibtex/0708">[bib]</a>
    </li>
</ul>

<h2>Journal Papers<small></small></h2>
<ul>
    <li>
        <span style="background-color: lightblue;">[<strong>J1</strong>] A Deep-Learning Approach for Low-Spatial-Coherence Imaging in Computer-Generated Holography.</span> <br>
        <span style="background-color: lightgray;">Xin Tong, Rux Xu, <strong>Ke Liu</strong>, Liangliang Zhao, Weilai Zhu, Daomu Zhao.</span> <br>
        <i style="background-color: lightpink;">Advanced Photonics Research.</i> <br>
        <a href="https://onlinelibrary.wiley.com/doi/10.1002/adpr.202200264">[paper]</a> 
        <a href="https://github.com/zjuKeLiu/U-RDN">[code]</a> 
        <a href="https://onlinelibrary.wiley.com/action/showCitFormats?doi=10.1002%2Fadpr.202200264">[bib]</a>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>J2</strong>] Low-Data Drug Design with Few-Shot Generative Domain Adaptation.</span> <br>
        <span style="background-color: lightgray;"><strong>Ke Liu</strong>, Yuqiang Han, Zhichen Gong, Hongxia Xu.</span> <br>
        <i style="background-color: lightpink;">BioEngineering.</i>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>J3</strong>] Collaborative knowledge amalgamation: Preserving discriminability and transferability in unsupervised learning.</span> <br>
        <span style="background-color: lightgray;">Shangde Gao*, Yichao Fu*, <strong>Ke Liu*</strong>, Wei Gao, Hongxia Xu, Jian Wu, Yuqiang Han.</span> <br>
        <i style="background-color: lightpink;">Information Sciences.</i>
    </li>
    <li>
        <span style="background-color: lightblue;">[<strong>J4</strong>] A periodicity aware transformer for crystal property prediction.</span> <br>
        <span style="background-color: lightgray;"><strong>Ke Liu</strong>, Kaifan Yang, Shangde Gao.</span> <br>
        <i style="background-color: lightpink;">Neural Computing and Applications.</i>
    </li>
</ul>

